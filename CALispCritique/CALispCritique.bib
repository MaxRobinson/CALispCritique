@phdthesis{Marthi:2006,
 author = {Marthi, Bhaskara Mannar},
 advisor = {Russell, Stuart},
 title = {Concurrent Hierarchical Reinforcement Learning},
 year = {2006},
 note = {AAI3253978},
 publisher = {University of California at Berkeley},
 address = {Berkeley, CA, USA},
}

@inproceedings{Andre:2002,
	author = {Andre, David and Russell, Stuart J.},
	title = {State Abstraction for Programmable Reinforcement Learning Agents},
	booktitle = {Eighteenth National Conference on Artificial Intelligence},
	year = {2002},
	isbn = {0-262-51129-0},
	location = {Edmonton, Alberta, Canada},
	pages = {119--125},
	numpages = {7},
	url = {http://dl.acm.org/citation.cfm?id=777092.777114},
	acmid = {777114},
	publisher = {American Association for Artificial Intelligence},
	address = {Menlo Park, CA, USA},
}

@book{Bertsekas:1996,
	author = {Bertsekas, Dimitri P. and Tsitsiklis, John N.},
	title = {Neuro-Dynamic Programming},
	year = {1996},
	isbn = {1886529108},
	edition = {1st},
	publisher = {Athena Scientific},
}

@book{Puterman:1994,
	author = {Puterman, Martin L.},
	title = {Markov Decision Processes: Discrete Stochastic Dynamic Programming},
	year = {1994},
	isbn = {0471619779},
	edition = {1st},
	publisher = {John Wiley \&amp; Sons, Inc.},
	address = {New York, NY, USA},
}

@Article{Watkins:1992,
	author="Watkins, Christopher J. C. H.
	and Dayan, Peter",
	title="Q-learning",
	journal="Machine Learning",
	year="1992",
	month="May",
	day="01",
	volume="8",
	number="3",
	pages="279--292",
	abstract="Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.",
	issn="1573-0565",
	doi="10.1007/BF00992698",
	url="https://doi.org/10.1007/BF00992698"
}

@book{Sutton:1998,
	author = {Sutton, Richard S. and Barto, Andrew G.},
	title = {Introduction to Reinforcement Learning},
	year = {1998},
	isbn = {0262193981},
	edition = {1st},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
}


